{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Configuración del Ambiente**\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "global df_traffic, resultados, modelo, modelo_clasificacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Creación de Modelo de Regresión Lineal**\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12283 entries, 0 to 12282\n",
      "Data columns (total 21 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   visitNumber         12283 non-null  int64  \n",
      " 1   browser             12283 non-null  int64  \n",
      " 2   operatingSystem     12283 non-null  int64  \n",
      " 3   deviceCategory      12283 non-null  int64  \n",
      " 4   continent           12283 non-null  int64  \n",
      " 5   country             12283 non-null  int64  \n",
      " 6   city                12283 non-null  int64  \n",
      " 7   networkDomain       12283 non-null  int64  \n",
      " 8   source              12283 non-null  int64  \n",
      " 9   medium              12283 non-null  int64  \n",
      " 10  keyword             12283 non-null  int64  \n",
      " 11  referralPath        12283 non-null  int64  \n",
      " 12  adContent           12283 non-null  int64  \n",
      " 13  pageviews           12283 non-null  int64  \n",
      " 14  newVisits           12283 non-null  float64\n",
      " 15  transactionRevenue  12283 non-null  float64\n",
      " 16  year                12283 non-null  int64  \n",
      " 17  day                 12283 non-null  int64  \n",
      " 18  weekday             12283 non-null  int64  \n",
      " 19  time_range          12283 non-null  int64  \n",
      " 20  Classifier          12283 non-null  int64  \n",
      "dtypes: float64(2), int64(19)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_traffic = pd.read_csv('Classifier.csv', sep=';')\n",
    "df_traffic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Total Bins 914\n",
      "[LightGBM] [Info] Number of data points in the train set: 9826, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 1.488793\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Mean Squared Error: 223.35476659731054\n"
     ]
    }
   ],
   "source": [
    "X = df_traffic.drop(columns=['transactionRevenue'])\n",
    "y = df_traffic['transactionRevenue']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression',       # Problema de regresión\n",
    "    'metric': 'mse',                 # Métrica de evaluación: Error cuadrático medio\n",
    "    'num_leaves': 31,                # Número máximo de hojas en un árbol\n",
    "    'learning_rate': 0.1,            # Tasa de aprendizaje\n",
    "    'max_depth': -1,                 # Profundidad máxima de cada árbol (-1 significa sin límite)\n",
    "    'min_child_samples': 20,         # Número mínimo de muestras necesarias para formar una nueva partición en un nodo\n",
    "    'reg_alpha': 0.0,                # Parámetro de regularización L1 (alpha)\n",
    "    'reg_lambda': 0.0,               # Parámetro de regularización L2 (lambda)\n",
    "    'n_estimators': 100,             # Número de árboles en el conjunto\n",
    "    'bagging_fraction': 0.8,         # Fracción de muestras para construir cada árbol (subsampling)\n",
    "    'feature_fraction': 0.8,         # Fracción de características para construir cada árbol (subsamplling de características)\n",
    "    'bagging_freq': 5,                # Frecuencia de subsampling (se realiza cada 5 iteraciones)\n",
    "    'force_col_wise': True          # Forzar el modo de entrenamiento de columnas\n",
    "}\n",
    "\n",
    "lgb_regressor = lgb.LGBMRegressor(**params)\n",
    "lgb_regressor.fit(X_train, y_train)\n",
    "y_pred = lgb_regressor.predict(X_test)\n",
    "\n",
    "# Calcular el error cuadrático medio (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definiendo el K - número de subconjuntos\n",
    "cv = KFold(n_splits = 5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_regressor = lgb.LGBMRegressor()\n",
    "\n",
    "# Definir los parámetros\n",
    "param_lgbm_regressor = {\n",
    "    'num_leaves': [31],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [-1],\n",
    "    'min_child_samples': [20],\n",
    "    'reg_alpha': [0.0],\n",
    "    'reg_lambda': [0.0],\n",
    "    'n_estimators': [100],\n",
    "    'bagging_fraction': [0.8],\n",
    "    'feature_fraction': [0.8],\n",
    "    'bagging_freq': [5],\n",
    "    'force_col_wise': [True]\n",
    "}\n",
    "\n",
    "# Configurar RandomizedSearchCV\n",
    "randomized_search_lgbm = RandomizedSearchCV(\n",
    "    estimator=lgbm_regressor,\n",
    "    param_distributions=param_lgbm_regressor,\n",
    "    n_iter=1,  # Solo se ajustará una vez\n",
    "    cv=5,  # Número de divisiones de validación cruzada\n",
    "    scoring='neg_mean_squared_error',  # Métrica de evaluación\n",
    "    n_jobs=-1,  # Utilizar todos los núcleos de la CPU\n",
    "    random_state=42  # Semilla aleatoria para reproducibilidad\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Total Bins 914\n",
      "[LightGBM] [Info] Number of data points in the train set: 9826, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 1.488793\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=LGBMRegressor(), n_iter=1, n_jobs=-1,\n",
       "                   param_distributions={&#x27;bagging_fraction&#x27;: [0.8],\n",
       "                                        &#x27;bagging_freq&#x27;: [5],\n",
       "                                        &#x27;feature_fraction&#x27;: [0.8],\n",
       "                                        &#x27;force_col_wise&#x27;: [True],\n",
       "                                        &#x27;learning_rate&#x27;: [0.1],\n",
       "                                        &#x27;max_depth&#x27;: [-1],\n",
       "                                        &#x27;min_child_samples&#x27;: [20],\n",
       "                                        &#x27;n_estimators&#x27;: [100],\n",
       "                                        &#x27;num_leaves&#x27;: [31], &#x27;reg_alpha&#x27;: [0.0],\n",
       "                                        &#x27;reg_lambda&#x27;: [0.0]},\n",
       "                   random_state=42, scoring=&#x27;neg_mean_squared_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5, estimator=LGBMRegressor(), n_iter=1, n_jobs=-1,\n",
       "                   param_distributions={&#x27;bagging_fraction&#x27;: [0.8],\n",
       "                                        &#x27;bagging_freq&#x27;: [5],\n",
       "                                        &#x27;feature_fraction&#x27;: [0.8],\n",
       "                                        &#x27;force_col_wise&#x27;: [True],\n",
       "                                        &#x27;learning_rate&#x27;: [0.1],\n",
       "                                        &#x27;max_depth&#x27;: [-1],\n",
       "                                        &#x27;min_child_samples&#x27;: [20],\n",
       "                                        &#x27;n_estimators&#x27;: [100],\n",
       "                                        &#x27;num_leaves&#x27;: [31], &#x27;reg_alpha&#x27;: [0.0],\n",
       "                                        &#x27;reg_lambda&#x27;: [0.0]},\n",
       "                   random_state=42, scoring=&#x27;neg_mean_squared_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LGBMRegressor(), n_iter=1, n_jobs=-1,\n",
       "                   param_distributions={'bagging_fraction': [0.8],\n",
       "                                        'bagging_freq': [5],\n",
       "                                        'feature_fraction': [0.8],\n",
       "                                        'force_col_wise': [True],\n",
       "                                        'learning_rate': [0.1],\n",
       "                                        'max_depth': [-1],\n",
       "                                        'min_child_samples': [20],\n",
       "                                        'n_estimators': [100],\n",
       "                                        'num_leaves': [31], 'reg_alpha': [0.0],\n",
       "                                        'reg_lambda': [0.0]},\n",
       "                   random_state=42, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajustar el modelo\n",
    "randomized_search_lgbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los mejores parámetros y la mejor puntuación\n",
    "best_params = randomized_search_lgbm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#el mejor score\n",
    "best_score = randomized_search_lgbm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'reg_lambda': 0.0, 'reg_alpha': 0.0, 'num_leaves': 31, 'n_estimators': 100, 'min_child_samples': 20, 'max_depth': -1, 'learning_rate': 0.1, 'force_col_wise': True, 'feature_fraction': 0.8, 'bagging_freq': 5, 'bagging_fraction': 0.8}\n",
      "Mejor puntuación: -344.9604636926821\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejores parámetros:\", best_params)\n",
    "print(\"Mejor puntuación:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Total Bins 914\n",
      "[LightGBM] [Info] Number of data points in the train set: 9826, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 1.488793\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Mean Squared Error: 223.35476659731054\n",
      "R^2 Score: 0.47984099519370427\n",
      "Root Mean Squared Error: 14.94505826677536\n"
     ]
    }
   ],
   "source": [
    "# Crear una nueva instancia de LGBMRegressor con los mejores parámetros encontrados\n",
    "best_lgbm = lgb.LGBMRegressor(**randomized_search_lgbm.best_params_)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "best_lgbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_lgbm.predict(X_test)\n",
    "\n",
    "# Calcular el MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calcular R^2\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R^2 Score:\", r2)\n",
    "\n",
    "# Calcular RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'LightGBMRegressor', 'mse': 223.35476659731054, 'r2': 0.47984099519370427, 'rmse': 14.94505826677536}\n"
     ]
    }
   ],
   "source": [
    "model_scores = {\n",
    "    'model': 'LightGBMRegressor',\n",
    "    'mse': mse,\n",
    "    'r2': r2,\n",
    "    'rmse': rmse\n",
    "}\n",
    "print(model_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_scores(model_scores: dict):\n",
    "  status = []\n",
    "  #Utilizamos un try-except en caso de que el archivo no exista que cree uno\n",
    "  try:\n",
    "    #Si el archivo existe continúa por acá\n",
    "    scores = pd.read_csv('scores.csv', sep=';')\n",
    "    status.append('El archivo existe')\n",
    "    exist = model_scores['model'] in scores['model'].values\n",
    "    #Validamos si el modelo ya existe en el archivo de scores\n",
    "    if (exist):\n",
    "      #Si el modelo ya existe reemplazamos sus valores\n",
    "      status.append('El modelo existe')\n",
    "      criteria = scores['model'] == model_scores['model']\n",
    "      index = scores[criteria].index[0]\n",
    "      scores.iloc[index] = model_scores\n",
    "      status.append('Se reemplazaron los valores del modelo')\n",
    "    else:\n",
    "      #Si el modelo no existe lo agregamos\n",
    "      status.append('El modelo no existe')\n",
    "      df_model_scores = pd.DataFrame(model_scores, index=[0])\n",
    "      scores = pd.concat([scores, df_model_scores], ignore_index=True)\n",
    "      status.append('Se añadió modelo nuevo y sus valores')\n",
    "  except:\n",
    "    #Si no existe el archivo lo creamos y cargamos los scores del modelo\n",
    "    status.append('El archivo no existe')\n",
    "    scores = pd.DataFrame(model_scores, index=[0])\n",
    "\n",
    "  status.append('Se sobrescrive el archivo scores.csv con valores nuevos')\n",
    "  scores.to_csv('scores.csv', sep=';', index=False)\n",
    "  return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El archivo existe',\n",
       " 'El modelo existe',\n",
       " 'Se reemplazaron los valores del modelo',\n",
       " 'Se sobrescrive el archivo scores.csv con valores nuevos']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_scores(model_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
